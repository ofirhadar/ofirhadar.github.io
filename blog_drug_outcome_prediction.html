<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unsupervised Semantic Segmentation with F-Seg</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            line-height: 1.6;
        }
        .nav-bar {
            background-color: #333;
            padding: 15px 0;
            position: sticky;
            top: 0;
            z-index: 100;
            text-align: center;
        }
        .nav-bar a {
            color: white;
            text-decoration: none;
            padding: 15px 25px;
            font-size: 1.1em;
        }
        .nav-bar a:hover {
            background-color: #555;
        }
        .container {
            max-width: 800px;
            margin: 40px auto;
            padding: 20px;
            background-color: #fff;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
        }
        h1, h2, h3 {
            color: #333;
        }
        h1 {
            text-align: center;
            margin-bottom: 30px;
        }
        h2 {
            margin-top: 40px;
            border-bottom: 2px solid #eee;
            padding-bottom: 10px;
        }
        h3 {
            margin-top: 25px;
        }
        .math {
            font-family: 'Times New Roman', serif;
            font-style: italic;
        }
        pre {
            background-color: #f8f8f8;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        code {
            font-family: 'Courier New', monospace;
        }
        p {
            margin-bottom: 20px;
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <div class="nav-bar">
        <a href="index.html">About Me</a>
        <a href="publications.html">Publications</a>
        <a href="patents.html">Patents</a>
        <a href="blogs.html">Blog</a>
    </div>
    <div class="container">
        <h1>Predicting Drug Outcomes from WSIs: MIL, Human-Interpretable Features, and Multimodal Fusion</h1>

        <p>In this post, we explore how whole slide images (WSIs) are used to predict drug outcomes — such as treatment response or survival — using two main strategies:

            Multiple Instance Learning (MIL), which leverages weak labels across gigapixel images, and
            
            Human-interpretable features (HiFs), which quantify biologically meaningful characteristics like TILs, necrosis, or glandular structure.
            
            We'll discuss these methods individually, then show how they can be combined in multimodal models to improve prediction performance and interpretability.</p>

        <section id="introduction">
            <h2>Introduction</h2>
            
            <p>
                WSIs are rich, high-resolution images that capture both the morphological and spatial heterogeneity of tissues. They are already used by pathologists for clinical diagnosis and grading, making them a natural candidate for predictive modeling. However, leveraging WSIs in a robust and interpretable way for predicting drug outcomes remains a challenge. This is due to several factors: the gigapixel size of the data, the lack of fine-grained annotations, and the need for models that provide actionable, trustworthy predictions.
            </p>
            
            <p>
                In recent years, two dominant modeling paradigms have emerged to tackle this problem:
            </p>
            
            <ul>
                <li><strong>Multiple Instance Learning (MIL)</strong>: A deep learning approach that treats WSIs as bags of instances (tiles), trained with only slide- or patient-level labels. MIL is particularly powerful in settings where detailed annotations are not available.</li>
                <li><strong>Human-Interpretable Features (HiFs)</strong>: An alternative or complementary approach that extracts domain-informed, biologically meaningful features from tissue (e.g., lymphocyte density, tumor-to-stroma ratio, necrosis) and uses them as inputs to predictive models. These features offer high clinical interpretability.</li>
            </ul>
            
        </section>
              

        <h2>Conclusion</h2>

        <p></p>
        
    </div>
</body>
</html>
