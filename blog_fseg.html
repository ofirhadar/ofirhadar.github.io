<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unsupervised Semantic Segmentation with F-Seg</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            line-height: 1.6;
        }
        .nav-bar {
            background-color: #333;
            padding: 15px 0;
            position: sticky;
            top: 0;
            z-index: 100;
            text-align: center;
        }
        .nav-bar a {
            color: white;
            text-decoration: none;
            padding: 15px 25px;
            font-size: 1.1em;
        }
        .nav-bar a:hover {
            background-color: #555;
        }
        .container {
            max-width: 800px;
            margin: 40px auto;
            padding: 20px;
            background-color: #fff;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
        }
        h1, h2, h3 {
            color: #333;
        }
        h1 {
            text-align: center;
            margin-bottom: 30px;
        }
        h2 {
            margin-top: 40px;
            border-bottom: 2px solid #eee;
            padding-bottom: 10px;
        }
        h3 {
            margin-top: 25px;
        }
        .math {
            font-family: 'Times New Roman', serif;
            font-style: italic;
        }
        pre {
            background-color: #f8f8f8;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        code {
            font-family: 'Courier New', monospace;
        }
        p {
            margin-bottom: 20px;
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <div class="nav-bar">
        <a href="index.html">About Me</a>
        <a href="publications.html">Publications</a>
        <a href="patents.html">Patents</a>
        <a href="blogs.html">Blog</a>
    </div>
    <div class="container">
        <h1>Unsupervised Semantic Segmentation with F-Seg</h1>

        <p>Unsupervised segmentation in digital pathology is a challenging problem. The F-Seg method leverages deep feature factorization (DFF) to extract meaningful concepts from image activations, enabling segmentation without labeled data. In this post, we explore the theoretical foundations of F-Seg, supported by mathematical formulations and practical Python code.</p>

        <img src="images/uni_luad_64.png" alt="F-Seg Pipeline" style="width: 50%; height: auto; display: block; margin: 0 auto;">

        <h2>Deep Feature Factorization (DFF) and Non-Negative Matrix Factorization (NMF)</h2>

        <h3>Theoretical Background</h3>

        <p>Given an input image \( I \), a deep network extracts activation maps \( A \in \mathbb{R}^{C \times rows \times cols} \), where \( C \) is the number of feature channels, and \( rows \times cols \) is the spatial resolution. Our goal is to decompose these activations into a set of interpretable components.</p>

        <p>DFF achieves this via Non-Negative Matrix Factorization (NMF). The activation tensor is reshaped into a matrix \( A \in \mathbb{R}^{C \times (rows \cdot cols)} \), and we seek a factorization:</p>

        <p>\[ A \approx W H \]</p>

        <p>where:</p>
        <ul>
            <li>\( W \in \mathbb{R}^{C \times K} \) represents the concept basis (semantic components), and</li>
            <li>\( H \in \mathbb{R}^{K \times (rows \cdot cols)} \) represents the concept activations per spatial location.</li>
        </ul>

        <p>The optimization problem solved by NMF is:</p>

        <p>\[ \min_{W, H} \| A - W H \|_F^2 \quad \text{subject to} \quad W \geq 0, H \geq 0 \]</p>

        <p>where \( \| \cdot \|_F \) denotes the Frobenius norm.</p>

        <h3>Why Non-Negative Matrix Factorization (NMF)?</h3>

        <p>NMF is particularly well-suited for unsupervised segmentation because it ensures that both the basis components and the activations are non-negative. This leads to parts-based representations, which aligns well with the idea of decomposing an image into meaningful segments. Unlike PCA, which allows both positive and negative values, NMF produces interpretable components that resemble actual object parts. Furthermore, compared to other matrix factorization techniques like ICA or SVD, NMF is more robust in extracting localized features, which is crucial in image segmentation tasks where spatial coherence is important.</p>

        <h3>Implementation</h3>

        <pre><code>import numpy as np
import torch
from sklearn.decomposition import NMF

# Perform Deep Feature Factorization using NMF
def dff(activations: np.ndarray, n_components: int = 5):
    batch_size, __, h, w = activations.shape
    reshaped_activations = activations.transpose((1, 0, 2, 3)).reshape(activations.shape[1], -1)
    model = NMF(n_components=n_components, init='random', random_state=0)
    H = model.fit_transform(reshaped_activations)
    W = model.components_.reshape(n_components, batch_size, h, w)
    return H, W.transpose((1, 0, 2, 3))

# Create segmentation mask from factorized components
def create_segmentation_mask(W: np.ndarray) -> np.ndarray:
    """
    Creates a segmentation mask by assigning each pixel to the dominant factor.
    
    Args:
        W: Component activations of shape (batch_size, n_components, height, width)
    Returns:
        Segmentation mask of shape (batch_size, height, width) with values 0 to n_components-1
    """
    # Get the dominant component at each spatial location
    segmentation = np.argmax(W, axis=1)
    return segmentation

# Example usage
activations = np.random.randn(10, 3, 10, 10)  # Example activations
n_components = 5  # Number of components to factorize into
H, W = dff(activations, n_components)

segmentation_mask = create_segmentation_mask(W)
</code></pre>

        <h2>Visualizing Segmentation</h2>

        <p>After factorization, we assign each pixel to the dominant factor, creating a segmentation mask. The following function overlays the segmentation results on the input image.</p>

        <pre><code>import matplotlib.pyplot as plt

def show_segmentation_on_image(img: np.uint8, segmentation: np.ndarray, colors=None, image_weight=0.5):
    float_img = np.float32(img) / 255
    n_categories = np.max(segmentation) + 1
    if colors is None:
        cmap = plt.cm.get_cmap('gist_rainbow')
        colors = [np.array(cmap(i)[:3]) for i in np.linspace(0, 1, n_categories)]
    mask = np.zeros_like(float_img)
    for category in range(n_categories):
        mask[segmentation == category] = colors[category]
    return np.uint8((float_img * image_weight + mask * (1 - image_weight)) * 255)</code></pre>

    <p>Below is an example of an input image and the corresponding segmentation mask generated using DFF:</p>
            
    <img src="images/fseg_color_example.png" alt="DFF Segmentation Example" style="width: 50%; height: auto;">

        <h2>F-Seg: From Factorization to Segmentation</h2>

        <p>F-Seg leverages DFF to extract semantic concepts from images, but concept extraction alone is not sufficient for robust segmentation. To achieve effective segmentation, F-Seg investigates two key approaches: (1) Clustering the extracted concepts into semantically meaningful groups, and (2) Solving the factorization problem with a fixed W matrix to align with predefined categories. These approaches build upon the basic DFF framework to enable more structured and reliable segmentation results.</p>

        <h3>Clustering Concepts</h3>

        <p>Once we obtain the matrix \( W \), we cluster the feature vectors into distinct semantic groups. Given a set of predefined cluster centroids \( C \), each feature vector \( w_i \) is assigned to the nearest cluster using cosine similarity:</p>

        <p>\[ \text{Label}(w_i) = \arg\min_j \frac{w_i \cdot C_j}{\|w_i\| \|C_j\|} \]</p>

        <img src="images/fseg_clustering_pipeline.png" alt="F-Seg Clustering Pipeline" style="width: 80%; height: auto; display: block; margin: 0 auto;">

        <h3>Solving NMF by Fixing \( W \)</h3>

        <p>This approach fixes the W matrix, which contains the concept features, and solves NMF only for H. By doing so, we can achieve segmentation into predefined concepts. The optimization problem becomes:</p>
        
        <p>\[ \min_{H} \| A - W H \|_F^2 \quad \text{subject to} \quad H \geq 0 \]</p>
        
        <img src="images/fseg_fixed_h_pipeline.png" alt="F-Seg with Fixed W Pipeline" style="width: 80%; height: auto; display: block; margin: 0 auto;">

        <p>This can be solved iteratively using multiplicative updates or gradient descent methods. Fixing \( W \) allows better control over the learned feature representations and enables structured segmentation patterns.</p>
        
        <h3>Applying F-Seg</h3>
        
        <pre><code># Example 1: Using predict_clustering for semantic segmentation
import torch
from torchvision.models import resnet50
import numpy as np
from PIL import Image
import torchvision.transforms as transforms

# Load model and create FSeg instance
model = resnet50(pretrained=True)
target_layer = model.layer4[-1]
fseg = FSeg(model=model, target_layer=target_layer)

# Define cluster centroids (e.g., from prior knowledge or clustering)
# Here we use example centroids for 3 categories (e.g., background, tissue, tumor)
cluster_centroids = np.array([
    [0.2, 0.3, 0.5],  # background features
    [0.6, 0.2, 0.2],  # tissue features
    [0.1, 0.7, 0.2]   # tumor features
])
clustering_model = ConceptClustering(cluster_centroids)

# Load and preprocess image
image = Image.open('pathology_sample.jpg')
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
input_tensor = transform(image).unsqueeze(0)

# Get clustered segmentation
segmentation = fseg.predict_clustering(
    input_tensor=input_tensor,
    clustering_model=clustering_model,
    k=10  # number of intermediate concepts
)

# Example 2: Using predict_project_concepts with fixed concepts
# Define concept features (e.g., from annotated examples)
# Here we use example concepts for 3 tissue types
concept_features = np.array([
    [0.8, 0.1, 0.1, 0.0, 0.0],  # concept 1 features
    [0.1, 0.7, 0.1, 0.1, 0.0],  # concept 2 features
    [0.0, 0.1, 0.1, 0.7, 0.1]   # concept 3 features
])

# Get segmentation with fixed concepts
segmentation = fseg.predict_project_concepts(
    input_tensor=input_tensor,
    concepts=concept_features
)

)</code></pre>

        <h3>One-Shot Segmentation with F-Seg</h3>

        <p>F-Seg can be used for one-shot segmentation. One-shot segmentation allows segmenting images with only one annotated example per category. The process involves:</p>
        
        <ol>
            <li>Selecting one annotation per category and extracting its feature embeddings as matrix \( W \).</li>
            <li>Fixing \( W \) in the NMF optimization:</li>
            <li>Using the learned \( H \) to segment new images by aligning them with the predefined categories.</li>
        </ol>
        <img src="images/oneshot.png" alt="F-Seg One-Shot Segmentation Example from DeepPathology STUDIO" style="width: 80%; height: auto; display: block; margin: 0 auto;">
        <h2>Conclusion</h2>

        <p>F-Seg enables unsupervised segmentation by leveraging feature factorization. The method decomposes high-dimensional feature spaces into semantic components, making it useful for pathology and other domains where labeled data is scarce. Experiment with different values of \( k \) to observe its effect on segmentation granularity!</p>
        
        <p>For more details and implementation, visit our <a href="https://github.com/deepathology/fseg">GitHub repository</a>.</p>
    </div>
</body>
</html>
